---
title: "Practical Machine Learning Project"
author: "Everett Robinson"
date: "May 23, 2017"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(caret)
set.seed(73222)
```

## Data Exploration and Cleaning
We start by importing the data from the provided csv files. For now I will only import the training data, as I am going to split this into a new training subset and a testing subset and use the provided pml-testing.csv file for final model validation.
```{r import}
raw_pml_training <- read.csv("pml-training.csv")
in_training <- createDataPartition(y = raw_pml_training$classe, p = 0.75, list = FALSE)
training <- raw_pml_training[in_training,]
testing <- raw_pml_training[-in_training,]

dim(training)
dim(testing)
```

It looks like there are a large number of rows of data to be used for training and testing, so I will stick with this simple data partition and not use any folding or resampling techniques on the data. There are a large number of predictors however so we will need to investigate these further.

```{r col_names}
names(training)
```

From the source of the data <http://groupware.les.inf.puc-rio.br/har>, we know that six different participants were asked to complete dumbbell bicep curls in five different ways, the first using proper technique and the next four using a variety of incorrect techniques. These differing techniques are identified in the classe variable using the letters A through E. We also know that the main components of the data come from four separate three axis accellerometers. One accelerometer was mounted on the dumbell, and three were located on the particiapants waist, forearm, and upper arm.

The first seven columns appear to be related to data collection rather than actual measurements, and they will need to be removed from each data frame before training is performed:
```{r}
head(training[1:7])
```

```{r}
non_measurement_columns <- 1:ncol(training) <= 7
```


Each accelerometer also recorded 38 different variables during each repitition:
```{r}
length(grep("dumbbell", names(training)))
length(grep("belt", names(training)))
length(grep("forearm", names(training)))
length(grep("_arm", names(training)))
```

These measurements are on various paramters such as roll, pitch, yaw, acceleration, gyros, and magnetic measurements. They are also supplemented by statistics for each measurement such as mean, minimum, maximum, amplitude, variance, standard deviation, skew, and kurtosis.

We hope that the combinations of all of the above will be sufficiently different between the different classe exercise techniques.

```{r}
ggplot(training) + geom_point(aes(x = X, y = roll_dumbbell, colour = classe), alpha = 0.2) + facet_wrap("user_name")
```


```{r}
ggplot(training) + geom_point(aes(x = X, y = pitch_dumbbell, colour = classe), alpha = 0.2) + facet_wrap("user_name")
```


```{r}
ggplot(training) + geom_point(aes(x = X, y = accel_dumbbell_y, colour = classe), alpha = 0.2) + facet_wrap("user_name")
```

It appears there is a lot of variation between how the different participants perform the dumbell curls, which reinforces the descision to remove the user_name column from the training data before training occurs to prevent it from playing a roll in the classification process. There are some visible differences between the classe groups as well, which suggests that the combination of multiple different accelerometer readings for each recorded exercise might be able to distinguish the techniques.

It is unlikely that all 38 columns from each accelerometer will be necessary to properly classify each excersice, and so we will remove or consolidate columns that don't offer a useful amount crutial to classification.

The first step in this process will be to figure out which columns are not well populated with data. After running **View(training)**, the columns containing the summary statistics appear to be very sparse. I suspect that it is the case that only the last row of data in each num_window set was populated with these values, and now they are spread across our training, testing, and validation data sets. Because it would be difficult to correct this issue while still maintaining the separation of the datasets, these columns are prime candidates for removal.

We will start by figuring out how sparse each column actually is:

```{r}
percent_sparse <- function(col) {
  sum((is.na(col) | col == "")/ length(col))
}

sparseness <- apply(training, 2, percent_sparse)

table(sparseness)
names(sparseness[sparseness > 0.95])
```

So it turns out that all of the columns containing summary statistics are nearly 98% empty. We will remove these when cleaning the data:
```{r}
sparse_columns <- sparseness > 0.95
```


The above preprocessing steps will need to be performed before the data is ready to be used for training. It is necessary that the same preprocessing steps be performed on each of the training, testing, and validation data frames, so I will put all of the steps in a function that can be run on all three data frames to ensure consistency.
```{r}
clean_data <- function(data) {
  drop_columns <- non_measurement_columns | sparse_columns
  data <- data[,!drop_columns]
  return(data)
}
```

## Model Building and Selection

